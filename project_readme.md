# ğŸ¤– Enhanced Emotion-Aware Chatbot

An advanced AI-powered chatbot that adapts its personality and responses based on real-time facial emotion detection. Built with Python, Flask, OpenCV, and Google's Generative AI, deployed on Google Cloud Run.

[![Cloud Run](https://img.shields.io/badge/Google%20Cloud-Run-blue?logo=google-cloud)](https://cloud.google.com/run)
[![Python](https://img.shields.io/badge/Python-3.11+-blue?logo=python)](https://python.org)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)
[![Status](https://img.shields.io/badge/Status-Production%20Ready-green.svg)]()

## âœ¨ Features

### Core Functionality
- ğŸ­ **Real-time Emotion Detection**: Advanced facial emotion recognition using DeepFace
- ğŸ¤– **Adaptive AI Responses**: Google Generative AI with emotion-aware personalities
- ğŸ’¬ **Conversation Context**: Maintains conversation history for natural interactions
- âš¡ **High Performance**: Optimized with caching, rate limiting, and auto-scaling

### Technical Features
- ğŸ”„ **Auto-reconnection**: Exponential backoff retry logic
- ğŸ“Š **Comprehensive Monitoring**: Health checks, metrics, and structured logging
- ğŸ›¡ï¸ **Security**: Rate limiting, input validation, and error handling
- ğŸ¯ **Testing Suite**: Automated API testing with detailed reporting
- ğŸ“± **Cross-platform Client**: Works on Windows, macOS, and Linux

### Cloud-Native Architecture
- â˜ï¸ **Google Cloud Run**: Serverless, auto-scaling deployment
- ğŸ—„ï¸ **Redis Caching**: Optional caching layer for improved performance
- ğŸ³ **Docker**: Containerized application with multi-stage builds
- ğŸ” **Security**: Non-root containers, secrets management

## ğŸš€ Quick Start

### 1. Prerequisites

```bash
# Required tools
- Google Cloud SDK
- Docker
- Python 3.11+
- Webcam (for client)
```

### 2. Deploy to Google Cloud

```bash
# Set up your project
export PROJECT_ID="your-project-id"
gcloud config set project $PROJECT_ID

# Enable APIs
gcloud services enable cloudbuild.googleapis.com run.googleapis.com

# Set your API key
gcloud secrets create GOOGLE_API_KEY --data-file=- <<< "your-google-ai-api-key"

# Deploy
gcloud builds submit --config cloudbuild.yaml .
```

### 3. Run the Client

```bash
# Install dependencies
pip install opencv-python requests

# Update server URL in local_client.py
CLOUD_SERVER_URL = "https://your-deployed-service-url"

# Launch the interactive client
python enhanced_local_client.py
```

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Local Client  â”‚â”€â”€â”€â–¶â”‚   Cloud Backend  â”‚â”€â”€â”€â–¶â”‚  Google AI API  â”‚
â”‚   (OpenCV +     â”‚    â”‚  (Flask + ML)    â”‚    â”‚   (Gemini)      â”‚
â”‚    Webcam)      â”‚    â”‚                  â”‚    â”‚                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                       â”‚                       
         â”‚                       â–¼                       
         â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             
         â”‚              â”‚   DeepFace ML    â”‚             
         â”‚              â”‚ (Emotion Model)  â”‚             
         â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             
         â”‚                       â”‚                       
         â–¼                       â–¼                       
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             
â”‚ Conversation    â”‚    â”‚  Redis Cache     â”‚             
â”‚ History (Local) â”‚    â”‚  (Optional)      â”‚             
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             
```

## ğŸ“Š API Endpoints

### Core Endpoints

| Endpoint | Method | Description | Rate Limit |
|----------|--------|-------------|------------|
| `/` | GET | API information | - |
| `/health` | GET | Health check and status | - |
| `/metrics` | GET | System metrics | - |
| `/detect_emotion` | POST | Analyze facial emotion | 30/min |
| `/chat` | POST | Basic chat interaction | 10/min |
| `/chat/context` | POST | Context-aware chat | 10/min |

### Request Examples

**Emotion Detection**:
```json
POST /detect_emotion
{
  "image": "base64-encoded-image-data"
}
```

**Chat**:
```json
POST /chat
{
  "user_input": "How are you today?",
  "emotion": "happy"
}
```

**Context Chat**:
```json
POST /chat/context
{
  "user_input": "What did we discuss?",
  "emotion": "neutral",
  "user_id": "unique-user-id"
}
```

## ğŸ­ Emotion-Based Personalities

The AI adapts its responses based on detected emotions:

- **ğŸ˜Š Happy**: Enthusiastic, encouraging, celebratory
- **ğŸ˜¢ Sad**: Gentle, empathetic, supportive
- **ğŸ˜ Neutral**: Balanced, informative, friendly
- **ğŸ˜  Angry**: Calm, patient, de-escalating
- **ğŸ˜² Surprised**: Curious, enthusiastic, wondering
- **ğŸ˜¨ Fearful**: Reassuring, comforting, protective
- **ğŸ¤¢ Disgusted**: Tactful, understanding, topic-changing

## ğŸ› ï¸ Development Setup

### Local Development

```bash
# Clone the repository
git clone <your-repo-url>
cd emotion-aware-chatbot

# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Set environment variables
export GOOGLE_API_KEY="your-api-key"
export FLASK_ENV="development"

# Run locally
python cloud_backend.py
```

### Docker Development

```bash
# Build the image
docker build -t emotion-ai .

# Run with environment variables
docker run -p 8080:8080 \
  -e GOOGLE_API_KEY="your-api-key" \
  -e FLASK_ENV="development" \
  emotion-ai
```

### Testing

```bash
# Run the comprehensive test suite
python enhanced_test_script.py

# Test specific functionality
curl -X GET http://localhost:8080/health
```

## ğŸ“ˆ Performance & Monitoring

### Built-in Monitoring

- **Health Checks**: `/health` endpoint with service status
- **Metrics Dashboard**: `/metrics` with performance data
- **Structured Logging**: JSON-formatted logs for analysis
- **Request Tracking**: Response times and error rates

### Performance Optimizations

- **Model Preloading**: Eliminates cold start delays
- **Redis Caching**: Caches similar emotion detections
- **Image Optimization**: Automatic resizing and compression
- **Connection Pooling**: Efficient HTTP connections
- **Rate Limiting**: Prevents resource exhaustion

### Scaling Configuration

```yaml
# Cloud Run auto-scaling settings
- Memory: 2GB (handles ML models)
- CPU: 2 vCPUs (parallel processing)
- Concurrency: 10 (balanced load)
- Max Instances: 5 (cost control)
- Min Instances: 1 (reduced cold starts)
```

## ğŸ” Security Features

### Implemented Security

- **Rate Limiting**: API abuse prevention
- **Input Validation**: Sanitization of all inputs
- **Error Handling**: Secure error responses
- **Non-root Containers**: Security hardening
- **HTTPS Enforcement**: Secure communications
- **Secrets Management**: Google Secret Manager integration

### Security Best Practices

```python
# Input validation example
def validate_image_data(image_data):
    if len(img_bytes) > MAX_IMAGE_SIZE:
        return False, "Image too large"
    # Additional validation...

# Rate limiting example
@limiter.limit("10 per minute")
def chat():
    # Protected endpoint
```

## ğŸ¯ Client Features

### Interactive Commands

- `help` - Show available commands
- `status` - Display connection and system status
- `history` - Show recent conversation history
- `save` - Export conversation to JSON file
- `clear` - Clear terminal screen
- `quit/exit/q` - Exit application

### Visual Feedback

The OpenCV window displays:
- **Current emotion** with confidence level
- **Connection status** (connected/disconnected)
- **Frame information** and processing stats
- **Color-coded confidence** (green/yellow/red)

### Conversation Management

- **Local History**: Automatically saved conversations
- **Context Awareness**: References previous messages
- **Export Capability**: Save conversations as JSON
- **Auto-reconnection**: Handles network interruptions

## ğŸ”§ Configuration

### Environment Variables

```bash
# Required
GOOGLE_API_KEY=your-google-ai-api-key

# Optional
REDIS_URL=redis://localhost:6379
MAX_IMAGE_SIZE=2097152
EMOTION_CONFIDENCE_THRESHOLD=0.7
FLASK_ENV=production
PORT=8080
```

### Client Configuration

```python
# In enhanced_local_client.py
CLOUD_SERVER_URL = "https://your-service-url"
FRAME_SKIP = 15  # Process every 15th frame
CONNECTION_TIMEOUT = 10
CHAT_TIMEOUT = 60
MAX_RETRIES = 3
```

## ğŸ“Š Usage Examples

### Basic Interaction

```bash
# Start the client
python enhanced_local_client.py

# The client will show:
You (neutral): Hello!
AI: Hello! I'm here and ready to chat. How can I help you today?

You (happy): I just got a promotion!
AI [with context]: That's absolutely wonderful news! Congratulations on your promotion! ğŸ‰ 
I can see you're really happy about it, and you should be! This is such an exciting achievement...
```

### API Usage

```python
import requests

# Detect emotion from image
response = requests.post(
    "https://your-service-url/detect_emotion",
    json={"image": base64_image}
)
emotion_data = response.json()

# Chat with detected emotion
response = requests.post(
    "https://your-service-url/chat/context",
    json={
        "user_input": "I'm feeling great today!",
        "emotion": emotion_data["emotion"],
        "user_id": "user123"
    }
)
chat_response = response.json()
```

## ğŸš¨ Troubleshooting

### Common Issues

**Issue**: "Could not open webcam"
```bash
# Solution: Check camera permissions and availability
ls /dev/video*  # Linux
# Ensure no other applications are using the camera
```

**Issue**: "Connection failed"
```bash
# Solution: Verify service URL and network connection
curl https://your-service-url/health
python enhanced_test_script.py
```

**Issue**: "Rate limit exceeded"
```bash
# Solution: Wait or implement request queuing
# Rate limits: 10 chat requests/minute, 30 emotion detections/minute
```

**Issue**: "Low emotion confidence"
```bash
# Solution: Improve lighting, face positioning
# Adjust EMOTION_CONFIDENCE_THRESHOLD if needed
```

### Debug Commands

```bash
# Check service logs
gcloud logs read --limit=50 "resource.type=cloud_run_revision"

# Test all endpoints
python enhanced_test_script.py

# Monitor system resources
curl https://your-service-url/metrics
```

## ğŸ”® Roadmap

### Planned Features

- **ğŸ™ï¸ Voice Integration**: Speech-to-text and text-to-speech
- **ğŸŒ WebSocket Support**: Real-time bidirectional communication
- **ğŸ“± Mobile Apps**: Native iOS and Android clients
- **ğŸ‘¥ Multi-user Support**: Room-based conversations
- **ğŸ§  Advanced Context**: Long-term memory and user profiles
- **ğŸ“Š Analytics Dashboard**: Usage insights and metrics
- **ğŸŒ Multi-language**: International language support
- **ğŸ¨ Custom Personalities**: User-defined AI personalities

### Technical Improvements

- **ğŸ”„ Event Streaming**: Apache Kafka integration
- **ğŸ—„ï¸ Database**: PostgreSQL for persistent storage
- **ğŸ” Search**: Conversation search and indexing
- **ğŸ¤– Model Updates**: Dynamic model versioning
- **âš–ï¸ Load Balancing**: Advanced traffic distribution

## ğŸ¤ Contributing

### Development Process

1. **Fork** the repository
2. **Create** a feature branch: `git checkout -b feature/amazing-feature`
3. **Commit** changes: `git commit -m 'Add amazing feature'`
4. **Push** to branch: `git push origin feature/amazing-feature`
5. **Open** a Pull Request

### Code Standards

- **Python**: Follow PEP 8 style guidelines
- **Testing**: Add tests for new features
- **Documentation**: Update README and docstrings
- **Security**: Follow security best practices

### Development Tools

```bash
# Code formatting
pip install black isort flake8

# Testing
pip install pytest pytest-flask pytest-cov

# Security scanning
pip install bandit safety
```

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- **DeepFace**: Facial emotion recognition
- **Google Generative AI**: Conversational AI capabilities
- **OpenCV**: Computer vision processing
- **Flask**: Web framework
- **Google Cloud**: Cloud infrastructure

## ğŸ“ Support

- **Issues**: [GitHub Issues](https://github.com/your-repo/issues)
- **Discussions**: [GitHub Discussions](https://github.com/your-repo/discussions)
- **Email**: your-email@example.com

## ğŸ“Š Project Stats

- **Language**: Python
- **Framework**: Flask
- **Deployment**: Google Cloud Run
- **ML Models**: DeepFace, Google Generative AI
- **Status**: Production Ready
- **Version**: 2.0.0

---

**Made with â¤ï¸ and ğŸ¤– by [Your Name]**

*Bringing emotions to AI conversations, one smile at a time.*